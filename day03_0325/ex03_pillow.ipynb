{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-25T07:36:26.276862Z",
     "start_time": "2024-03-25T07:36:26.266391Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모듈 로딩\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 이미지 데이터 로딩\n",
    "file = '../data/img/img_06_sg.jpg'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T07:36:26.292813Z",
     "start_time": "2024-03-25T07:36:26.279083Z"
    }
   },
   "id": "3c02c1391eb941c5",
   "execution_count": 377
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEG 562 420 RGB <class 'PIL.JpegImagePlugin.JpegImageFile'>\n"
     ]
    }
   ],
   "source": [
    "img = Image.open(fp = file)\n",
    "print(img.format, img.height, img.width, img.mode, type(img))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T07:36:26.308597Z",
     "start_time": "2024-03-25T07:36:26.293878Z"
    }
   },
   "id": "e850203803cfe1ef",
   "execution_count": 378
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 562, 420]) 3\n",
      "tensor([[0.2039, 0.2078, 0.2353,  ..., 0.0784, 0.0745, 0.0706],\n",
      "        [0.2235, 0.2235, 0.2588,  ..., 0.0824, 0.0784, 0.0745],\n",
      "        [0.2549, 0.2588, 0.2824,  ..., 0.0863, 0.0824, 0.0824],\n",
      "        ...,\n",
      "        [0.1608, 0.1647, 0.1765,  ..., 0.0392, 0.0392, 0.0392],\n",
      "        [0.1412, 0.1608, 0.1686,  ..., 0.0392, 0.0392, 0.0392],\n",
      "        [0.1412, 0.1608, 0.1686,  ..., 0.0392, 0.0392, 0.0392]])\n"
     ]
    }
   ],
   "source": [
    "# 사용법 \n",
    "# - (1) 인스턴스 생성\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# - (2) 인스턴스 변수 사용\n",
    "imgTS = to_tensor(img)\n",
    "\n",
    "# - (3) 변환된 이미지 텐서 확인\n",
    "print(imgTS.shape, imgTS.ndim)\n",
    "print(imgTS[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T07:36:26.324535Z",
     "start_time": "2024-03-25T07:36:26.310703Z"
    }
   },
   "id": "ede6104d682be2b3",
   "execution_count": 379
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (562, 420, 3) 3\n",
      "<class 'numpy.ndarray'> (562, 420, 3) 3\n",
      "torch.Size([3, 562, 420]) 3 tensor([[0.0627, 0.0549, 0.0667,  ..., 0.0314, 0.0275, 0.0235],\n",
      "        [0.0627, 0.0549, 0.0784,  ..., 0.0353, 0.0314, 0.0275],\n",
      "        [0.0706, 0.0627, 0.0784,  ..., 0.0392, 0.0353, 0.0353],\n",
      "        ...,\n",
      "        [0.0235, 0.0275, 0.0314,  ..., 0.0392, 0.0392, 0.0392],\n",
      "        [0.0157, 0.0353, 0.0353,  ..., 0.0392, 0.0392, 0.0392],\n",
      "        [0.0157, 0.0353, 0.0353,  ..., 0.0392, 0.0392, 0.0392]])\n",
      "torch.Size([3, 562, 420]) 3 tensor([[0.2039, 0.2078, 0.2353,  ..., 0.0784, 0.0745, 0.0706],\n",
      "        [0.2235, 0.2235, 0.2588,  ..., 0.0824, 0.0784, 0.0745],\n",
      "        [0.2549, 0.2588, 0.2824,  ..., 0.0863, 0.0824, 0.0824],\n",
      "        ...,\n",
      "        [0.1608, 0.1647, 0.1765,  ..., 0.0392, 0.0392, 0.0392],\n",
      "        [0.1412, 0.1608, 0.1686,  ..., 0.0392, 0.0392, 0.0392],\n",
      "        [0.1412, 0.1608, 0.1686,  ..., 0.0392, 0.0392, 0.0392]])\n"
     ]
    }
   ],
   "source": [
    "# openCV\n",
    "import cv2\n",
    "my_img = cv2.imread(file)\n",
    "my_img_02 = cv2.cvtColor(my_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "print(type(my_img), my_img.shape, my_img.ndim)\n",
    "print(type(my_img_02), my_img_02.shape, my_img_02.ndim)\n",
    "\n",
    "# 텐서화\n",
    "imgTS_2 = to_tensor(my_img)\n",
    "imgTS_3 = to_tensor(my_img_02)\n",
    "\n",
    "print(imgTS_2.shape, imgTS_2.ndim, imgTS_2[0])\n",
    "print(imgTS_3.shape, imgTS_3.ndim, imgTS_3[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T07:36:26.356600Z",
     "start_time": "2024-03-25T07:36:26.327732Z"
    }
   },
   "id": "2477e164fbbea802",
   "execution_count": 380
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# resize\n",
    "preprocessing = transforms.Compose(transforms = [\n",
    "    transforms.Resize(size = (50, 50)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T07:36:26.371686Z",
     "start_time": "2024-03-25T07:36:26.359035Z"
    }
   },
   "id": "195c49d9c73a530c",
   "execution_count": 381
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.3176, 0.2980, 0.2431,  ..., 0.8392, 0.3294, 0.1098],\n         [0.5333, 0.7020, 0.6471,  ..., 0.6824, 0.2000, 0.1255],\n         [0.6431, 0.9098, 0.9333,  ..., 0.4588, 0.1216, 0.1176],\n         ...,\n         [0.2196, 0.2902, 0.3098,  ..., 0.0353, 0.0353, 0.0353],\n         [0.2392, 0.2510, 0.2706,  ..., 0.0392, 0.0392, 0.0392],\n         [0.2039, 0.2039, 0.2902,  ..., 0.0431, 0.0431, 0.0392]],\n\n        [[0.0784, 0.0941, 0.0863,  ..., 0.7686, 0.2353, 0.0902],\n         [0.1725, 0.4235, 0.3725,  ..., 0.6235, 0.1216, 0.0980],\n         [0.3059, 0.8118, 0.8431,  ..., 0.4314, 0.1059, 0.1020],\n         ...,\n         [0.0980, 0.1098, 0.1137,  ..., 0.0353, 0.0353, 0.0353],\n         [0.1059, 0.1020, 0.1059,  ..., 0.0392, 0.0392, 0.0392],\n         [0.0980, 0.0980, 0.1137,  ..., 0.0431, 0.0431, 0.0392]],\n\n        [[0.0510, 0.0471, 0.0510,  ..., 0.3882, 0.0980, 0.0549],\n         [0.0667, 0.2196, 0.2039,  ..., 0.4039, 0.0588, 0.0745],\n         [0.1255, 0.6196, 0.6510,  ..., 0.3098, 0.0627, 0.0745],\n         ...,\n         [0.0392, 0.0510, 0.0549,  ..., 0.0353, 0.0353, 0.0353],\n         [0.0431, 0.0431, 0.0471,  ..., 0.0392, 0.0392, 0.0392],\n         [0.0431, 0.0431, 0.0549,  ..., 0.0431, 0.0431, 0.0392]]])"
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing(img)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T07:36:26.387915Z",
     "start_time": "2024-03-25T07:36:26.373787Z"
    }
   },
   "id": "3bd4d9f812b3530e",
   "execution_count": 382
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 이미지 데이터셋 <hr>\n",
    "- torchvision.ImageFoler 클래스 사용\n",
    "    * 이미지 데이터 라벨링\n",
    "    * 이미지 데이터 전처리"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d406b6fb00e3f0f4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T07:36:26.403013Z",
     "start_time": "2024-03-25T07:36:26.390480Z"
    }
   },
   "id": "99355349af01de68",
   "execution_count": 383
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "img_root = '../data/img'\n",
    "imgDS = ImageFolder(root = img_root, transform = preprocessing)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T07:36:26.418344Z",
     "start_time": "2024-03-25T07:36:26.405234Z"
    }
   },
   "id": "ce706c661cd5fc09",
   "execution_count": 384
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[('../data/img\\\\folder1\\\\111.jpg', 0),\n ('../data/img\\\\folder1\\\\222.jpg', 0),\n ('../data/img\\\\folder1\\\\333.jpg', 0),\n ('../data/img\\\\folder1\\\\444.jpg', 0),\n ('../data/img\\\\folder1\\\\555.jpg', 0),\n ('../data/img\\\\folder1\\\\666.jpg', 0),\n ('../data/img\\\\folder1\\\\777.jpg', 0),\n ('../data/img\\\\folder2\\\\gray_3.jpg', 1)]"
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 폴더명이 분류 클래스\n",
    "imgDS.classes\n",
    "\n",
    "# 폴더명이 분류 클래스가 숫자로 바뀜\n",
    "imgDS.class_to_idx\n",
    "\n",
    "imgDS.imgs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T07:36:26.433428Z",
     "start_time": "2024-03-25T07:36:26.421567Z"
    }
   },
   "id": "e83bd8f05828b800",
   "execution_count": 385
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 50, 50]) torch.Size([1])\n",
      "torch.Size([1, 3, 50, 50]) torch.Size([1])\n",
      "torch.Size([1, 3, 50, 50]) torch.Size([1])\n",
      "torch.Size([1, 3, 50, 50]) torch.Size([1])\n",
      "torch.Size([1, 3, 50, 50]) torch.Size([1])\n",
      "torch.Size([1, 3, 50, 50]) torch.Size([1])\n",
      "torch.Size([1, 3, 50, 50]) torch.Size([1])\n",
      "torch.Size([1, 3, 50, 50]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "imgDL = DataLoader(dataset = imgDS)\n",
    "for (img, label) in imgDL:\n",
    "    print(img.shape, label.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T07:36:26.541215Z",
     "start_time": "2024-03-25T07:36:26.435512Z"
    }
   },
   "id": "b9f786f858269a50",
   "execution_count": 386
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T07:36:26.556375Z",
     "start_time": "2024-03-25T07:36:26.543324Z"
    }
   },
   "id": "1f90e2f2a2707331",
   "execution_count": 386
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
